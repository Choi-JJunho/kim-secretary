# ì´ë ¥ì„œ í‰ê°€ ì‹œìŠ¤í…œ ê°œë°œ ê°€ì´ë“œ

ìƒˆë¡œìš´ íšŒì‚¬/ì§êµ°ì˜ ì´ë ¥ì„œ í‰ê°€ í”Œë¡œìš°ë¥¼ ê°œë°œí•  ë•Œ ì°¸ê³ í•˜ëŠ” ê°€ì´ë“œì…ë‹ˆë‹¤.

## ê°œìš”

ì´ ì‹œìŠ¤í…œì€ íŠ¹ì • íšŒì‚¬ì˜ ì±„ìš©ê³µê³ ë¥¼ ìŠ¤í¬ë˜í•‘í•˜ì—¬ ì¸ì¬ìƒ/ìš”êµ¬ì‚¬í•­ì„ ì¶”ì¶œí•˜ê³ , ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ AIê°€ ì´ë ¥ì„œë¥¼ í‰ê°€í•˜ëŠ” ì›Œí¬í”Œë¡œìš°ì…ë‹ˆë‹¤.

### í”Œë¡œìš°
1. **ì§êµ° ë¶„ë¥˜**: ì´ë ¥ì„œë¥¼ ë¶„ì„í•˜ì—¬ ì í•©í•œ ì§êµ° ì¶”ì²œ
2. **ìŠ¤í¬ë˜í•‘**: í•´ë‹¹ ì§êµ°ì˜ ì±„ìš©ê³µê³ ì—ì„œ ì¸ì¬ìƒ/ìš”êµ¬ì‚¬í•­ ìˆ˜ì§‘
3. **í”„ë¡¬í”„íŠ¸ ìƒì„±**: ì¸ì¬ìƒ ê¸°ë°˜ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±
4. **í‰ê°€**: AI Agentê°€ ì´ë ¥ì„œ í‰ê°€

---

## ìƒˆ íšŒì‚¬ ì¶”ê°€ ì‹œ í•„ìš”í•œ ì •ë³´

ì‚¬ìš©ìê°€ ë‹¤ìŒ ì •ë³´ë¥¼ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤:

1. **íšŒì‚¬ ì •ë³´**
   - íšŒì‚¬ëª… (ì˜ë¬¸, í•œê¸€)
   - ì±„ìš© ì‚¬ì´íŠ¸ URL
   - ì±„ìš©ê³µê³  ìƒì„¸ í˜ì´ì§€ URL íŒ¨í„´

2. **ì§êµ° ì •ë³´**
   - ì§êµ° ëª©ë¡ (ì˜ˆ: Backend, Frontend, App, DevOps ë“±)
   - ê° ì§êµ°ë³„ ì±„ìš©ê³µê³  ID ë˜ëŠ” URL

3. **Slack ì±„ë„ ì •ë³´**
   - ì´ë ¥ì„œ í”¼ë“œë°± ì±„ë„ ID

4. **HTML êµ¬ì¡°** (ìŠ¤í¬ë˜í•‘ìš©)
   - ì±„ìš©ê³µê³  í˜ì´ì§€ì˜ HTML ìƒ˜í”Œ
   - ì¸ì¬ìƒ/ìš”êµ¬ì‚¬í•­/ê¸°ìˆ ìŠ¤íƒ ì„¹ì…˜ì˜ ì„ íƒì(selector)

---

## ê°œë°œ ì ˆì°¨

### Step 1: ì§êµ° Enum ì •ì˜ (`models.py`)

```python
# src/resume_evaluator/models.pyì— ì¶”ê°€

class {Company}JobCategory(str, Enum):
    """íšŒì‚¬ëª… ì±„ìš© ì§êµ° ì¹´í…Œê³ ë¦¬"""
    BACKEND = "Backend"
    FRONTEND = "Frontend"
    APP = "App"
    # ... ì±„ìš© ì‚¬ì´íŠ¸ì˜ ì§êµ° í•„í„° ê¸°ì¤€ìœ¼ë¡œ ì¶”ê°€

# ì§êµ° ë§¤í•‘ (í•„ìš” ì‹œ)
{COMPANY}_TO_POSITION_MAPPING = {
    {Company}JobCategory.BACKEND: PositionCategory.BACKEND,
    {Company}JobCategory.FRONTEND: PositionCategory.FRONTEND,
    # ...
}
```

### Step 2: ìŠ¤í¬ë˜í¼ êµ¬í˜„ (`scraper_{company}.py`)

ìƒˆ íŒŒì¼ `src/resume_evaluator/scraper_{company}.py` ìƒì„±:

> **ê¶Œì¥**: ì •ì  job_id ëŒ€ì‹  **ë™ì  íƒìƒ‰ ë°©ì‹**ì„ ì‚¬ìš©í•˜ì„¸ìš”. ì±„ìš© ì‚¬ì´íŠ¸ëŠ” ìì£¼ ë³€ê²½ë˜ë¯€ë¡œ, í‚¤ì›Œë“œ ê¸°ë°˜ ë™ì  íƒìƒ‰ì´ ìœ ì§€ë³´ìˆ˜ì— ìœ ë¦¬í•©ë‹ˆë‹¤.

```python
"""íšŒì‚¬ëª… ì±„ìš©ê³µê³  ìŠ¤í¬ë˜í¼ (Playwright ê¸°ë°˜) - ë™ì  íƒìƒ‰"""

import asyncio
import json
import logging
from datetime import datetime
from pathlib import Path
from typing import Optional

from playwright.async_api import async_playwright, Page
from .models import JobRequirement, ScrapedData, {Company}JobCategory

logger = logging.getLogger(__name__)


class {Company}JobScraper:
    """íšŒì‚¬ëª… ì±„ìš©ê³µê³  ìŠ¤í¬ë˜í¼ - ë™ì  íƒìƒ‰"""

    BASE_URL = "https://careers.{company}.com"

    # ì§êµ°ë³„ í‚¤ì›Œë“œ ë§¤í•‘ (ì œëª©/íƒœê·¸ì—ì„œ ë§¤ì¹­)
    # ì •ì  job_id ëŒ€ì‹  í‚¤ì›Œë“œë¡œ ë™ì  ë¶„ë¥˜
    CATEGORY_KEYWORDS: dict[{Company}JobCategory, list[str]] = {
        {Company}JobCategory.BACKEND: [
            "server", "backend", "ë°±ì—”ë“œ", "ì„œë²„ ê°œë°œ",
        ],
        {Company}JobCategory.FRONTEND: [
            "frontend", "í”„ë¡ íŠ¸ì—”ë“œ", "web developer",
        ],
        # ... ì§êµ°ë³„ í‚¤ì›Œë“œ ì¶”ê°€
    }

    def __init__(self, data_dir: str = "data/resume_evaluator/{company}"):
        self.data_dir = Path(data_dir)
        self.data_dir.mkdir(parents=True, exist_ok=True)
        self.scraped_data_path = self.data_dir / "scraped_positions.json"

    async def scrape_positions_by_category(
        self,
        category: {Company}JobCategory,
        headless: bool = True,
        max_jobs: int = 10
    ) -> ScrapedData:
        """íŠ¹ì • ì§êµ°ì˜ í¬ì§€ì…˜ ìŠ¤í¬ë˜í•‘ (ë™ì  íƒìƒ‰)"""
        positions = []

        async with async_playwright() as p:
            browser = await p.chromium.launch(headless=headless)
            page = await browser.new_page()

            try:
                # ì±„ìš© ëª©ë¡ í˜ì´ì§€ë¡œ ì´ë™
                await page.goto(self.BASE_URL)
                await page.wait_for_timeout(2000)

                # í˜ì´ì§€ë¥¼ ìˆœíšŒí•˜ë©° ìŠ¤í¬ë˜í•‘
                page_num = 1
                scraped_count = 0

                while scraped_count < max_jobs:
                    logger.info(f"ğŸ“„ í˜ì´ì§€ {page_num} ìŠ¤í¬ë˜í•‘ ì¤‘...")

                    # í˜„ì¬ í˜ì´ì§€ì—ì„œ í•´ë‹¹ ì¹´í…Œê³ ë¦¬ ê³µê³  ìŠ¤í¬ë˜í•‘
                    page_positions = await self._scrape_page_positions(
                        page, category, max_jobs - scraped_count
                    )
                    positions.extend(page_positions)
                    scraped_count += len(page_positions)

                    if scraped_count >= max_jobs:
                        break

                    # ë‹¤ìŒ í˜ì´ì§€ë¡œ ì´ë™ (ì‚¬ì´íŠ¸ êµ¬ì¡°ì— ë§ê²Œ êµ¬í˜„)
                    if not await self._goto_next_page(page, page_num + 1):
                        break
                    page_num += 1
                    await page.wait_for_timeout(1000)

            except Exception as e:
                logger.error(f"âŒ ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨: {e}")
            finally:
                await browser.close()

        return ScrapedData(
            positions=positions,
            scraped_at=datetime.now(),
            source_url=f"{self.BASE_URL}?category={category.value}",
        )

    async def _scrape_page_positions(
        self,
        page: Page,
        category: {Company}JobCategory,
        max_count: int
    ) -> list[JobRequirement]:
        """í˜„ì¬ í˜ì´ì§€ì—ì„œ ê³µê³  ìŠ¤í¬ë˜í•‘ - íšŒì‚¬ë³„ HTML êµ¬ì¡°ì— ë§ê²Œ êµ¬í˜„"""

        # JavaScriptë¡œ ë°ì´í„° ì¶”ì¶œ (íšŒì‚¬ í˜ì´ì§€ êµ¬ì¡°ì— ë§ê²Œ ìˆ˜ì •)
        data = await page.evaluate("""
            (categoryKeywords) => {
                const jobs = [];

                // TODO: íšŒì‚¬ í˜ì´ì§€ì˜ HTML êµ¬ì¡°ì— ë§ê²Œ ì„ íƒì ìˆ˜ì •
                const jobCards = document.querySelectorAll('.job-card');

                for (const card of jobCards) {
                    const title = card.querySelector('.job-title')?.textContent?.trim() || '';
                    const tags = card.querySelector('.job-tags')?.textContent?.toLowerCase() || '';

                    // í‚¤ì›Œë“œ ë§¤ì¹­ìœ¼ë¡œ ì¹´í…Œê³ ë¦¬ í•„í„°ë§
                    const searchText = `${title} ${tags}`.toLowerCase();
                    const matches = categoryKeywords.some(kw => searchText.includes(kw));
                    if (!matches) continue;

                    // ìƒì„¸ ì •ë³´ ì¶”ì¶œ (ì‚¬ì´íŠ¸ êµ¬ì¡°ì— ë”°ë¼ ë‹¤ë¦„)
                    jobs.push({
                        title: title,
                        requirements: [],  // ìƒì„¸ í˜ì´ì§€ì—ì„œ ì¶”ì¶œí•˜ê±°ë‚˜ ëª©ë¡ì—ì„œ ì¶”ì¶œ
                        preferred: [],
                        tech_stack: [],
                        responsibilities: [],
                    });
                }

                return jobs;
            }
        """, self.CATEGORY_KEYWORDS.get(category, []))

        positions = []
        for item in data[:max_count]:
            if not item.get("title"):
                continue

            position = JobRequirement(
                title=item["title"],
                company="{Company}",
                requirements=item.get("requirements", []),
                preferred=item.get("preferred", []),
                tech_stack=item.get("tech_stack", []),
                responsibilities=item.get("responsibilities", []),
                job_id=f"{company}_{hash(item['title']) % 100000:05d}",
                category=category,
                scraped_at=datetime.now(),
            )
            positions.append(position)
            logger.info(f"âœ… {position.title} ìŠ¤í¬ë˜í•‘ ì™„ë£Œ")

        return positions

    async def _goto_next_page(self, page: Page, next_page_num: int) -> bool:
        """ë‹¤ìŒ í˜ì´ì§€ë¡œ ì´ë™ - ì‚¬ì´íŠ¸ êµ¬ì¡°ì— ë§ê²Œ êµ¬í˜„"""
        try:
            # TODO: ì‚¬ì´íŠ¸ì˜ í˜ì´ì§€ë„¤ì´ì…˜ êµ¬ì¡°ì— ë§ê²Œ ìˆ˜ì •
            next_link = page.locator(f'a.pagination:has-text("{next_page_num}")')
            if await next_link.count() > 0:
                await next_link.click()
                await page.wait_for_timeout(1500)
                return True
            return False
        except Exception:
            return False
```

#### ë™ì  íƒìƒ‰ vs ì •ì  job_id

| ë°©ì‹ | ì¥ì  | ë‹¨ì  |
|------|------|------|
| **ë™ì  íƒìƒ‰ (ê¶Œì¥)** | ì‚¬ì´íŠ¸ ë³€ê²½ì— ìœ ì—°, ìƒˆ ê³µê³  ìë™ ê°ì§€ | í‚¤ì›Œë“œ ë§¤í•‘ í•„ìš”, ì´ˆê¸° êµ¬í˜„ ë³µì¡ |
| **ì •ì  job_id** | êµ¬í˜„ ë‹¨ìˆœ, ì •í™•í•œ íƒ€ê²ŸíŒ… | ì‚¬ì´íŠ¸ ë³€ê²½ ì‹œ ìˆ˜ë™ ì—…ë°ì´íŠ¸ í•„ìš” |

ê¸°ì¡´ í† ìŠ¤/ì¹´í˜24 ìŠ¤í¬ë˜í¼ëŠ” ë™ì  íƒìƒ‰ ë°©ì‹ìœ¼ë¡œ êµ¬í˜„ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì°¸ê³ : `scraper.py`, `scraper_cafe24.py`

### Step 3: ì§êµ° ë¶„ë¥˜ê¸° í™•ì¥ (`job_classifier.py`)

```python
# CATEGORY_KEYWORDSì— ìƒˆ íšŒì‚¬ì˜ í‚¤ì›Œë“œ ì¶”ê°€ (í•„ìš” ì‹œ)
# ê¸°ì¡´ í‚¤ì›Œë“œëŠ” ëŒ€ë¶€ë¶„ ë²”ìš©ì ì´ë¯€ë¡œ ì¬ì‚¬ìš© ê°€ëŠ¥

# _str_to_category ë©”ì„œë“œì— ìƒˆ íšŒì‚¬ ì¹´í…Œê³ ë¦¬ ë§¤í•‘ ì¶”ê°€
def _str_to_category(self, s: str, company: str = "toss") -> Optional[Enum]:
    if company == "{company}":
        mapping = {
            "backend": {Company}JobCategory.BACKEND,
            # ...
        }
    else:
        mapping = {
            "backend": TossJobCategory.BACKEND,
            # ...
        }
    return mapping.get(s.lower().strip())
```

### Step 4: í”„ë¡¬í”„íŠ¸ ìƒì„±ê¸° (`prompt_generator_{company}.py`)

íšŒì‚¬ë³„ ë„ë©”ì¸/ì¸ì¬ìƒì´ ë‹¤ë¥´ë¯€ë¡œ ë³„ë„ íŒŒì¼ë¡œ êµ¬í˜„í•˜ê±°ë‚˜, ê¸°ì¡´ `PromptGenerator`ë¥¼ ìƒì†:

```python
class {Company}PromptGenerator(PromptGenerator):
    """íšŒì‚¬ëª… ì „ìš© í”„ë¡¬í”„íŠ¸ ìƒì„±ê¸°"""

    def _build_prompt(self, ...):
        # íšŒì‚¬ íŠ¹ì„±ì— ë§ê²Œ í‰ê°€ ê¸°ì¤€ ìˆ˜ì •
        # ì˜ˆ: ê¸ˆìœµ ëŒ€ì‹  ì´ì»¤ë¨¸ìŠ¤ ë„ë©”ì¸ í‰ê°€
        # ì˜ˆ: ê¸°ìˆ  ìŠ¤íƒ ìš°ì„ ìˆœìœ„ ì¡°ì •
        pass
```

### Step 5: ì›Œí¬í”Œë¡œìš° í†µí•© (`workflow_{company}.py`)

```python
class {Company}EvaluationWorkflow(ResumeEvaluationWorkflow):
    """íšŒì‚¬ëª… ì´ë ¥ì„œ í‰ê°€ ì›Œí¬í”Œë¡œìš°"""

    def __init__(self, config: WorkflowConfig):
        super().__init__(config)
        # íšŒì‚¬ ì „ìš© ìŠ¤í¬ë˜í¼ ì‚¬ìš©
        self.scraper = {Company}JobScraper(data_dir=f"{self.config.data_dir}/{company}")
        self.prompt_generator = {Company}PromptGenerator(data_dir=f"{self.config.data_dir}/{company}")
```

### Step 6: Slack í•¸ë“¤ëŸ¬ ì—°ë™ (`resume_handler.py`)

```python
# í™˜ê²½ë³€ìˆ˜ ì¶”ê°€
{COMPANY}_RESUME_FEEDBACK_CHANNEL_ID = os.getenv("{COMPANY}_RESUME_FEEDBACK_CHANNEL_ID")

# ì±„ë„ë³„ íšŒì‚¬ ë§¤í•‘
CHANNEL_COMPANY_MAP = {
    SLACK_RESUME_FEEDBACK_CHANNEL_ID: "toss",
    {COMPANY}_RESUME_FEEDBACK_CHANNEL_ID: "{company}",
}

# í•¸ë“¤ëŸ¬ì—ì„œ íšŒì‚¬ë³„ ì›Œí¬í”Œë¡œìš° ì„ íƒ
async def handle_resume_evaluation(channel_id: str, file_path: str):
    company = CHANNEL_COMPANY_MAP.get(channel_id, "toss")

    if company == "toss":
        workflow = ResumeEvaluationWorkflow(config)
    elif company == "{company}":
        workflow = {Company}EvaluationWorkflow(config)

    return await workflow.evaluate_with_classification(file_path)
```

### Step 7: í™˜ê²½ë³€ìˆ˜ ì¶”ê°€

`.env` íŒŒì¼ì— ì¶”ê°€:
```
{COMPANY}_RESUME_FEEDBACK_CHANNEL_ID=C0XXXXXXX
```

---

## ê¸°ì¡´ í† ìŠ¤ êµ¬í˜„ ì°¸ê³ 

í˜„ì¬ í† ìŠ¤ ì´ë ¥ì„œ í‰ê°€ ì‹œìŠ¤í…œì˜ êµ¬ì¡°:

```
src/resume_evaluator/
â”œâ”€â”€ __init__.py           # ëª¨ë“ˆ exports
â”œâ”€â”€ models.py             # TossJobCategory, JobRequirement, ScrapedData ë“±
â”œâ”€â”€ scraper.py            # TossJobScraper (Playwright ê¸°ë°˜)
â”œâ”€â”€ job_classifier.py     # JobClassifier (AI ë¶„ë¥˜)
â”œâ”€â”€ prompt_generator.py   # PromptGenerator (í‰ê°€ í”„ë¡¬í”„íŠ¸)
â”œâ”€â”€ evaluator.py          # ResumeEvaluator (AI í‰ê°€)
â”œâ”€â”€ workflow.py           # ResumeEvaluationWorkflow (ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜)
â””â”€â”€ cli.py                # CLI ì¸í„°í˜ì´ìŠ¤
```

### í•µì‹¬ ë°ì´í„° ëª¨ë¸

```python
@dataclass
class JobRequirement:
    title: str
    company: str
    requirements: list[str]    # ì¸ì¬ìƒ/ìê²©ìš”ê±´
    preferred: list[str]       # ìš°ëŒ€ì‚¬í•­
    tech_stack: list[str]      # ê¸°ìˆ ìŠ¤íƒ
    responsibilities: list[str]  # ì£¼ìš”ì—…ë¬´
    job_id: str
    category: PositionCategory
    scraped_at: datetime

@dataclass
class ScrapedData:
    positions: list[JobRequirement]
    scraped_at: datetime
    source_url: str
    content_hash: str  # ë³€ê²½ ê°ì§€ìš©

@dataclass
class ClassificationResult:
    primary_category: TossJobCategory
    secondary_categories: list[TossJobCategory]
    confidence: float
    reasoning: str
    skills_detected: list[str]
    experience_years: Optional[int]

@dataclass
class EvaluationResult:
    total_score: int  # 0-100
    grade: EvaluationGrade  # S/A/B/C/D
    scores: dict  # ì„¸ë¶€ ì ìˆ˜
    strengths: list[str]
    weaknesses: list[str]
    recommended_positions: list[str]
    interview_questions: list[str]
    summary: str
```

### ìŠ¤í¬ë˜í•‘ ì‹œ ì£¼ì˜ì‚¬í•­

1. **Rate Limiting**: ìš”ì²­ ì‚¬ì´ 1ì´ˆ ì´ìƒ ëŒ€ê¸°
2. **Headless ëª¨ë“œ**: í”„ë¡œë•ì…˜ì—ì„œëŠ” `headless=True`
3. **ìºì‹±**: `scraped_{category}.json`ìœ¼ë¡œ ì¹´í…Œê³ ë¦¬ë³„ ìºì‹±
4. **í•´ì‹œ ê¸°ë°˜ ë³€ê²½ ê°ì§€**: `content_hash`ë¡œ ë¶ˆí•„ìš”í•œ ì¬ìƒì„± ë°©ì§€
5. **ë™ì  íƒìƒ‰ ê¶Œì¥**: ì •ì  job_id ëŒ€ì‹  í‚¤ì›Œë“œ ê¸°ë°˜ ë™ì  íƒìƒ‰ ì‚¬ìš©
6. **í˜ì´ì§€ë„¤ì´ì…˜/ë¬´í•œìŠ¤í¬ë¡¤**: ì‚¬ì´íŠ¸ êµ¬ì¡°ì— ë§ê²Œ êµ¬í˜„ í•„ìš”

### í‰ê°€ ê¸°ì¤€ (í† ìŠ¤ ê¸°ì¤€)

- í•µì‹¬ ê¸°ìˆ  ì—­ëŸ‰: 40ì  (ì‹œìŠ¤í…œì„¤ê³„ 15 + íŠ¸ë˜í”½ì²˜ë¦¬ 15 + ê¸°ìˆ ìŠ¤íƒ 10)
- ë¬¸ì œ í•´ê²° ëŠ¥ë ¥: 25ì  (ì¥ì• ëŒ€ì‘ 15 + ë¬¸ì œí•´ê²° 10)
- ì†Œí”„íŠ¸ ìŠ¤í‚¬: 20ì  (ì£¼ë„ì„± 10 + í˜‘ì—… 5 + ì„±ì¥ 5)
- ë„ë©”ì¸ ì í•©ì„±: 15ì  (ê¸ˆìœµ/í•€í…Œí¬ 10 + B2C 5)

---

## ì²´í¬ë¦¬ìŠ¤íŠ¸

ìƒˆ íšŒì‚¬ ì¶”ê°€ ì‹œ ì²´í¬ë¦¬ìŠ¤íŠ¸:

- [ ] `models.py`ì— `{Company}JobCategory` Enum ì¶”ê°€
- [ ] `scraper_{company}.py` ìŠ¤í¬ë˜í¼ êµ¬í˜„ (ë™ì  íƒìƒ‰ ë°©ì‹ ê¶Œì¥)
- [ ] ì±„ìš©ê³µê³  HTML êµ¬ì¡° ë¶„ì„ ë° ì„ íƒì ì„¤ì •
- [ ] `CATEGORY_KEYWORDS` ì§êµ°ë³„ í‚¤ì›Œë“œ ë§¤í•‘ (ë™ì  íƒìƒ‰ ì‹œ)
- [ ] `prompt_generator_{company}.py` (í•„ìš” ì‹œ) í‰ê°€ ê¸°ì¤€ ì»¤ìŠ¤í„°ë§ˆì´ì§•
- [ ] `workflow_{company}.py` ì›Œí¬í”Œë¡œìš° í†µí•©
- [ ] `resume_handler.py` Slack í•¸ë“¤ëŸ¬ ì—°ë™
- [ ] `.env`ì— ì±„ë„ ID í™˜ê²½ë³€ìˆ˜ ì¶”ê°€
- [ ] `__init__.py` exports ì¶”ê°€
- [ ] í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„± (`scripts/test_{company}_eval.py`)
- [ ] Docker ë¹Œë“œ ë° ë°°í¬

---

## ì˜ˆì‹œ: ì¹´ì¹´ì˜¤ ì¶”ê°€ ìš”ì²­

ì‚¬ìš©ìê°€ ë‹¤ìŒê³¼ ê°™ì´ ìš”ì²­í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

> "ì¹´ì¹´ì˜¤ Backend ê°œë°œì ì´ë ¥ì„œ í‰ê°€ í”Œë¡œìš°ë¥¼ ì¶”ê°€í•´ì¤˜.
> - ì±„ìš© ì‚¬ì´íŠ¸: https://careers.kakao.com
> - ì§êµ°: Backend, Frontend, App, DevOps, Data
> - Slack ì±„ë„ ID: C05XXXXXX
> - (HTML ìƒ˜í”Œ ì²¨ë¶€)"

ì´ ê²½ìš° ìœ„ ì ˆì°¨ì— ë”°ë¼:
1. `KakaoJobCategory` Enum ìƒì„±
2. `KakaoJobScraper` êµ¬í˜„ (HTML êµ¬ì¡° ë¶„ì„ í•„ìš”)
3. `KakaoEvaluationWorkflow` ìƒì„±
4. Slack í•¸ë“¤ëŸ¬ ì—°ë™
