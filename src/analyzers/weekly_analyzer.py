"""ì£¼ê°„ ì—…ë¬´ì¼ì§€ ë¶„ì„ê¸°"""

import logging
import os
from typing import Dict, List, Optional

import pytz

from .. import ai

logger = logging.getLogger(__name__)

# KST timezone
KST = pytz.timezone('Asia/Seoul')


def _load_weekly_analysis_prompt() -> str:
  """ì£¼ê°„ ë¶„ì„ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ë¡œë“œ"""
  prompt_file = os.path.join(
      os.path.dirname(__file__),
      "..",
      "prompts",
      "weekly_report_analysis.txt"
  )

  try:
    with open(prompt_file, "r", encoding="utf-8") as f:
      return f.read()
  except FileNotFoundError:
    logger.warning(f"âš ï¸ Prompt file not found: {prompt_file}")
    return ""


class WeeklyAnalyzer:
  """ì£¼ê°„ ì—…ë¬´ì¼ì§€ ë¶„ì„ê¸°"""

  def __init__(self, ai_provider_type: str = "claude"):
    """
    Initialize WeeklyAnalyzer

    Args:
        ai_provider_type: AI provider type (gemini, claude, ollama)
    """
    self.ai_provider_type = ai_provider_type
    self.ai_provider = ai.get_ai_provider(ai_provider_type)
    self.last_used_ai_provider: Optional[str] = None

    # Load prompt template
    self.prompt_template = _load_weekly_analysis_prompt()
    logger.info(f"âœ… WeeklyAnalyzer initialized (AI: {ai_provider_type})")

  def extract_work_log_content(self, page: Dict) -> Dict[str, any]:
    """
    Notion íŽ˜ì´ì§€ì—ì„œ ì—…ë¬´ì¼ì§€ ë‚´ìš© ì¶”ì¶œ

    Args:
        page: Notion page object

    Returns:
        ì—…ë¬´ì¼ì§€ ë©”íƒ€ë°ì´í„° ë° ì½˜í…ì¸ 
    """
    properties = page.get("properties", {})

    # ë‚ ì§œ ì¶”ì¶œ
    date_prop = properties.get("ìž‘ì„±ì¼", {}).get("date", {})
    date = date_prop.get("start", "") if date_prop else ""

    # ì œëª© ì¶”ì¶œ
    title_prop = properties.get("Name", {}) or properties.get("ì œëª©", {})
    title_parts = title_prop.get("title", [])
    title = "".join([part.get("plain_text", "") for part in title_parts])

    # ê¸°ìˆ ìŠ¤íƒ ì¶”ì¶œ
    tech_stack_prop = properties.get("ê¸°ìˆ ìŠ¤íƒ", {}).get("multi_select", [])
    tech_stack = [item.get("name", "") for item in tech_stack_prop]

    # í”„ë¡œì íŠ¸ ì¶”ì¶œ
    project_prop = properties.get("í”„ë¡œì íŠ¸", {}).get("select", {})
    project = project_prop.get("name", "") if project_prop else ""

    # ì„±ê³¼íƒ€ìž… ì¶”ì¶œ
    achievement_type_prop = properties.get("ì„±ê³¼íƒ€ìž…", {}).get("select", {})
    achievement_type = achievement_type_prop.get(
        "name", "") if achievement_type_prop else ""

    # ì •ëŸ‰ì ì„±ê³¼ ì¶”ì¶œ
    quantitative_prop = properties.get("ì •ëŸ‰ì ì„±ê³¼", {}).get("rich_text", [])
    quantitative = "".join([part.get("plain_text", "")
                           for part in quantitative_prop])

    return {
      "date": date,
      "title": title,
      "tech_stack": tech_stack,
      "project": project,
      "achievement_type": achievement_type,
      "quantitative": quantitative,
      "page_id": page.get("id", "")
    }

  async def get_page_content(self, page_id: str, notion_client) -> str:
    """
    íŽ˜ì´ì§€ ë³¸ë¬¸ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°

    Args:
        page_id: Notion page ID
        notion_client: NotionClient instance

    Returns:
        íŽ˜ì´ì§€ ë³¸ë¬¸ í…ìŠ¤íŠ¸
    """
    try:
      blocks_response = await notion_client.client.blocks.children.list(
          block_id=page_id
      )
      blocks = blocks_response.get("results", [])

      content_parts = []
      for block in blocks:
        block_type = block.get("type")
        block_content = block.get(block_type, {})

        if "rich_text" in block_content:
          for text_obj in block_content["rich_text"]:
            if "text" in text_obj:
              content_parts.append(text_obj["text"]["content"])

      return "\n".join(content_parts)
    except Exception as e:
      logger.error(f"âŒ Failed to get page content: {e}")
      return ""

  async def analyze_weekly_logs(
      self,
      daily_logs: List[Dict],
      notion_client,
      resume_page_id: Optional[str] = None
  ) -> str:
    """
    ì£¼ê°„ ì—…ë¬´ì¼ì§€ ë¶„ì„

    Args:
        daily_logs: ì¼ì¼ ì—…ë¬´ì¼ì§€ íŽ˜ì´ì§€ ëª©ë¡
        notion_client: NotionClient instance
        resume_page_id: ì´ë ¥ì„œ íŽ˜ì´ì§€ ID (ì„ íƒ)

    Returns:
        ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì˜ ë¶„ì„ ê²°ê³¼
    """
    try:
      logger.info(f"ðŸ“Š ì£¼ê°„ ë¶„ì„ ì‹œìž‘: {len(daily_logs)}ê°œ ì—…ë¬´ì¼ì§€")

      # ì—…ë¬´ì¼ì§€ ë‚´ìš© ì¶”ì¶œ
      work_logs_data = []
      for page in daily_logs:
        metadata = self.extract_work_log_content(page)
        content = await self.get_page_content(metadata["page_id"], notion_client)

        work_log_text = f"""
## {metadata['date']} - {metadata['title']}
**í”„ë¡œì íŠ¸**: {metadata['project']}
**ì„±ê³¼íƒ€ìž…**: {metadata['achievement_type']}
**ê¸°ìˆ ìŠ¤íƒ**: {', '.join(metadata['tech_stack'])}
**ì •ëŸ‰ì ì„±ê³¼**: {metadata['quantitative']}

{content}
"""
        work_logs_data.append(work_log_text.strip())

      # ì „ì²´ ì—…ë¬´ì¼ì§€ í…ìŠ¤íŠ¸ ê²°í•©
      combined_logs = "\n\n---\n\n".join(work_logs_data)

      # ì´ë ¥ì„œ ë‚´ìš© ì½ê¸° (ìžˆëŠ” ê²½ìš°)
      resume_content = ""
      if resume_page_id:
        try:
          logger.info(f"ðŸ“„ ì´ë ¥ì„œ íŽ˜ì´ì§€ ì½ê¸°: {resume_page_id}")
          resume_content = await self.get_page_content(resume_page_id, notion_client)
          if resume_content:
            logger.info(f"âœ… ì´ë ¥ì„œ ë‚´ìš© ë¡œë“œ ì™„ë£Œ ({len(resume_content)}ìž)")
          else:
            logger.warning("âš ï¸ ì´ë ¥ì„œ íŽ˜ì´ì§€ê°€ ë¹„ì–´ìžˆìŠµë‹ˆë‹¤")
        except Exception as e:
          logger.warning(f"âš ï¸ ì´ë ¥ì„œ ì½ê¸° ì‹¤íŒ¨ (ì„ íƒì‚¬í•­): {e}")
          resume_content = ""

      # í”„ë¡¬í”„íŠ¸ ìƒì„±
      prompt = self.prompt_template.replace("{work_logs}", combined_logs)
      prompt = prompt.replace("{resume_content}", resume_content if resume_content else "(ì´ë ¥ì„œ ì •ë³´ ì—†ìŒ)")

      logger.info(f"ðŸ¤– AI ë¶„ì„ ì‹œìž‘... (ë‚´ìš© ê¸¸ì´: {len(combined_logs)}ìž)")

      # AI ë¶„ì„ ì‹¤í–‰
      analysis_text, used_provider = await ai.generate_with_gemini_fallback(
          self.ai_provider_type,
          prompt=prompt,
          system_prompt="ë‹¹ì‹ ì€ ì†Œí”„íŠ¸ì›¨ì–´ ì—”ì§€ë‹ˆì–´ì˜ ì—…ë¬´ ê¸°ë¡ì„ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ìž…ë‹ˆë‹¤. ë°˜ë“œì‹œ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”."
      )

      self.last_used_ai_provider = used_provider
      logger.info(f"âœ… AI ë¶„ì„ ì™„ë£Œ (ì œê³µìž: {used_provider})")
      logger.info(f"ðŸ“‹ ë¶„ì„ ê²°ê³¼ ì¶”ì¶œ ì™„ë£Œ")

      return analysis_text

    except Exception as e:
      logger.error(f"âŒ ì£¼ê°„ ë¶„ì„ ì‹¤íŒ¨: {e}")
      raise


# Singleton instance
_weekly_analyzer = None


def get_weekly_analyzer(ai_provider_type: str = "claude") -> WeeklyAnalyzer:
  """
  Get or create singleton WeeklyAnalyzer instance

  Args:
      ai_provider_type: AI provider type (gemini, claude, ollama)

  Returns:
      WeeklyAnalyzer instance
  """
  global _weekly_analyzer
  if _weekly_analyzer is None or _weekly_analyzer.ai_provider_type != ai_provider_type:
    _weekly_analyzer = WeeklyAnalyzer(ai_provider_type=ai_provider_type)
  return _weekly_analyzer
