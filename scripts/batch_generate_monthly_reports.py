"""
ì›”ê°„ ë¦¬í¬íŠ¸ ë°°ì¹˜ ìƒì„± ìŠ¤í¬ë¦½íŠ¸

ì£¼ê°„ ë¦¬í¬íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ ëˆ„ë½ëœ ì›”ê°„ ë¦¬í¬íŠ¸ë¥¼ ìë™ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
3ê°œì”© ë¹„ë™ê¸°ë¡œ ë™ì‹œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
"""

import asyncio
import json
import logging
import os
import sys
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Set, Tuple

import pytz
from dotenv import load_dotenv

# Load .env file from project root
project_root = Path(__file__).parent.parent
env_file = project_root / '.env'
if env_file.exists():
  load_dotenv(env_file)
  print(f"âœ… Loaded environment from {env_file}")
else:
  print(f"âš ï¸ No .env file found at {env_file}")

# Add project root to path
sys.path.insert(0, str(project_root))

from src.common.notion_utils import get_user_database_mapping
from src.notion.client import NotionClient
from src.notion.monthly_report_agent import get_monthly_report_manager

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

KST = pytz.timezone('Asia/Seoul')

# Configuration
BATCH_SIZE = 3  # ë™ì‹œ ì²˜ë¦¬ ê°œìˆ˜ (ì›”ê°„ ë¦¬í¬íŠ¸ëŠ” ë” ë¬´ê±°ìš°ë¯€ë¡œ 3ê°œ)
AI_PROVIDER = "claude"  # ì‚¬ìš©í•  AI ì œê³µì


class MonthlyReportBatchGenerator:
  """ì›”ê°„ ë¦¬í¬íŠ¸ ë°°ì¹˜ ìƒì„±ê¸°"""

  def __init__(
      self,
      user_id: str,
      ai_provider: str = "claude",
      batch_size: int = 3
  ):
    """
    Initialize batch generator

    Args:
        user_id: Slack user ID
        ai_provider: AI provider type
        batch_size: ë™ì‹œ ì²˜ë¦¬í•  ì›”ê°„ ë¦¬í¬íŠ¸ ê°œìˆ˜
    """
    self.user_id = user_id
    self.ai_provider = ai_provider
    self.batch_size = batch_size
    self.notion_client = NotionClient()
    self.monthly_manager = get_monthly_report_manager(ai_provider)

    # Get user database mappings
    user_dbs = get_user_database_mapping(user_id)
    if not user_dbs:
      raise ValueError(f"No database mapping found for user: {user_id}")

    self.weekly_report_db_id = user_dbs.get("weekly_report_db")
    self.monthly_report_db_id = user_dbs.get("monthly_report_db")

    if not self.weekly_report_db_id or not self.monthly_report_db_id:
      raise ValueError(f"Incomplete database mapping for user: {user_id}")

    logger.info(
        f"âœ… Initialized for user {user_id} (AI: {ai_provider}, "
        f"batch_size: {batch_size})"
    )

  async def get_weekly_report_dates(self) -> List[str]:
    """
    ì£¼ê°„ ë¦¬í¬íŠ¸ DBì—ì„œ ëª¨ë“  ì‹œì‘ì¼ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.

    Returns:
        ë‚ ì§œ ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸ (YYYY-MM-DD)
    """
    logger.info("ğŸ“… ì£¼ê°„ ë¦¬í¬íŠ¸ ë‚ ì§œ ì¡°íšŒ ì¤‘...")

    try:
      results = await self.notion_client.query_database(
          database_id=self.weekly_report_db_id,
          filter_params=None
      )

      dates = []
      for page in results:
        properties = page.get("properties", {})
        date_prop = properties.get("ì‹œì‘ì¼", {}).get("date", {})

        if date_prop:
          date_str = date_prop.get("start")
          if date_str:
            dates.append(date_str)

      # Sort dates in Python
      dates.sort()

      logger.info(f"âœ… ì´ {len(dates)}ê°œì˜ ì£¼ê°„ ë¦¬í¬íŠ¸ ë°œê²¬")
      return dates

    except Exception as e:
      logger.error(f"âŒ ì£¼ê°„ ë¦¬í¬íŠ¸ ë‚ ì§œ ì¡°íšŒ ì‹¤íŒ¨: {e}")
      raise

  async def get_existing_monthly_reports(self) -> Set[str]:
    """
    ì´ë¯¸ ìƒì„±ëœ ì›”ê°„ ë¦¬í¬íŠ¸ì˜ ë…„-ì›” ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.

    Returns:
        ë…„-ì›” ë¬¸ìì—´ ì§‘í•© (ì˜ˆ: {"2025-01", "2025-02"})
    """
    logger.info("ğŸ“Š ê¸°ì¡´ ì›”ê°„ ë¦¬í¬íŠ¸ ì¡°íšŒ ì¤‘...")

    try:
      results = await self.notion_client.query_database(
          database_id=self.monthly_report_db_id,
          filter_params=None
      )

      existing_months = set()
      for page in results:
        properties = page.get("properties", {})

        # ë…„ì›” ì†ì„±ì—ì„œ ì¶”ì¶œ
        month_prop = properties.get("ë…„ì›”", {})
        title_parts = month_prop.get("title", [])

        if title_parts:
          month_str = title_parts[0].get("plain_text", "")
          if month_str and len(month_str) == 7:  # YYYY-MM í˜•ì‹
            existing_months.add(month_str)

      logger.info(f"âœ… ê¸°ì¡´ ì›”ê°„ ë¦¬í¬íŠ¸: {len(existing_months)}ê°œ")
      return existing_months

    except Exception as e:
      logger.error(f"âŒ ì›”ê°„ ë¦¬í¬íŠ¸ ì¡°íšŒ ì‹¤íŒ¨: {e}")
      raise

  def group_dates_by_month(self, dates: List[str]) -> Dict[str, List[str]]:
    """
    ë‚ ì§œë¥¼ ë…„-ì›”ë¡œ ê·¸ë£¹í™”í•©ë‹ˆë‹¤.

    Args:
        dates: ë‚ ì§œ ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸

    Returns:
        ë…„-ì›”ë³„ ë‚ ì§œ ë”•ì…”ë„ˆë¦¬
    """
    months = {}

    for date_str in dates:
      try:
        date = datetime.fromisoformat(date_str)
        month_key = f"{date.year}-{date.month:02d}"

        if month_key not in months:
          months[month_key] = []
        months[month_key].append(date_str)

      except (ValueError, IndexError):
        logger.warning(f"âš ï¸ Invalid date format: {date_str}")
        continue

    return months

  async def generate_monthly_report(
      self,
      year: int,
      month: int,
      semaphore: asyncio.Semaphore
  ) -> Tuple[str, bool, str]:
    """
    ì›”ê°„ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤ (ë™ì‹œ ì‹¤í–‰ ì œí•œ ì ìš©).

    Args:
        year: ì—°ë„
        month: ì›”
        semaphore: ë™ì‹œ ì‹¤í–‰ ì œí•œìš© Semaphore

    Returns:
        (month_str, success, message) íŠœí”Œ
    """
    month_str = f"{year}-{month:02d}"

    async with semaphore:
      logger.info(f"ğŸ”„ [{month_str}] ì›”ê°„ ë¦¬í¬íŠ¸ ìƒì„± ì‹œì‘...")

      try:
        result = await self.monthly_manager.generate_monthly_report(
            year=year,
            month=month,
            weekly_report_database_id=self.weekly_report_db_id,
            monthly_report_database_id=self.monthly_report_db_id,
            progress_callback=None  # ë°°ì¹˜ ëª¨ë“œì—ì„œëŠ” progress ì½œë°± ì—†ìŒ
        )

        page_url = result.get('page_url', '')
        weekly_reports_count = result.get('weekly_reports_count', 0)

        logger.info(
            f"âœ… [{month_str}] ì™„ë£Œ! (ì£¼ê°„ ë¦¬í¬íŠ¸: {weekly_reports_count}ê°œ)"
        )

        return month_str, True, page_url

      except ValueError as e:
        # ì£¼ê°„ ë¦¬í¬íŠ¸ê°€ ì—†ëŠ” ê²½ìš° ë“±
        logger.warning(f"âš ï¸ [{month_str}] ê±´ë„ˆëœ€: {e}")
        return month_str, False, str(e)

      except Exception as e:
        logger.error(f"âŒ [{month_str}] ì‹¤íŒ¨: {e}")
        return month_str, False, str(e)

  async def generate_missing_reports(
      self,
      missing_months: List[Tuple[int, int]]
  ) -> Dict[str, any]:
    """
    ëˆ„ë½ëœ ì›”ê°„ ë¦¬í¬íŠ¸ë¥¼ ë°°ì¹˜ë¡œ ìƒì„±í•©ë‹ˆë‹¤.

    Args:
        missing_months: (year, month) íŠœí”Œ ë¦¬ìŠ¤íŠ¸

    Returns:
        ìƒì„± ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    if not missing_months:
      logger.info("âœ… ìƒì„±í•  ì›”ê°„ ë¦¬í¬íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
      return {
        "total": 0,
        "success": 0,
        "failed": 0,
        "skipped": 0,
        "results": []
      }

    logger.info(f"\n{'='*60}")
    logger.info(f"ğŸ“¦ ë°°ì¹˜ ìƒì„± ì‹œì‘: {len(missing_months)}ê°œ ì›”")
    logger.info(f"âš™ï¸ ë™ì‹œ ì²˜ë¦¬: {self.batch_size}ê°œ")
    logger.info(f"ğŸ¤– AI: {self.ai_provider}")
    logger.info(f"{'='*60}\n")

    # Semaphore for limiting concurrent tasks
    semaphore = asyncio.Semaphore(self.batch_size)

    # Create tasks
    tasks = []
    for year, month in missing_months:
      task = self.generate_monthly_report(year, month, semaphore)
      tasks.append(task)

    # Execute all tasks
    results = await asyncio.gather(*tasks, return_exceptions=True)

    # Analyze results
    success_count = 0
    failed_count = 0
    skipped_count = 0
    details = []

    for result in results:
      if isinstance(result, Exception):
        failed_count += 1
        details.append({
          "month": "unknown",
          "success": False,
          "message": str(result)
        })
      else:
        month_str, success, message = result
        if success:
          success_count += 1
        elif "ê±´ë„ˆëœ€" in message or "ì—†ìŒ" in message:
          skipped_count += 1
        else:
          failed_count += 1

        details.append({
          "month": month_str,
          "success": success,
          "message": message
        })

    logger.info(f"\n{'='*60}")
    logger.info(f"âœ… ë°°ì¹˜ ìƒì„± ì™„ë£Œ!")
    logger.info(f"{'='*60}")
    logger.info(f"ğŸ“Š ì´ ì‹œë„: {len(missing_months)}ê°œ")
    logger.info(f"âœ… ì„±ê³µ: {success_count}ê°œ")
    logger.info(f"âš ï¸ ê±´ë„ˆëœ€: {skipped_count}ê°œ")
    logger.info(f"âŒ ì‹¤íŒ¨: {failed_count}ê°œ")
    logger.info(f"{'='*60}\n")

    return {
      "total": len(missing_months),
      "success": success_count,
      "failed": failed_count,
      "skipped": skipped_count,
      "results": details
    }

  async def run(self) -> Dict[str, any]:
    """
    ë°°ì¹˜ ìƒì„± í”„ë¡œì„¸ìŠ¤ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.

    Returns:
        ì‹¤í–‰ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    try:
      # 1. Get all weekly report dates
      weekly_report_dates = await self.get_weekly_report_dates()

      if not weekly_report_dates:
        logger.info("âš ï¸ ì£¼ê°„ ë¦¬í¬íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return {"total": 0, "success": 0, "failed": 0, "skipped": 0}

      # 2. Group by month
      months_with_reports = self.group_dates_by_month(weekly_report_dates)
      logger.info(f"ğŸ“… ì£¼ê°„ ë¦¬í¬íŠ¸ê°€ ìˆëŠ” ì›”: {len(months_with_reports)}ê°œ")

      # 3. Get existing monthly reports
      existing_reports = await self.get_existing_monthly_reports()

      # 4. Find missing months
      missing_month_strs = set(months_with_reports.keys()) - existing_reports
      missing_months = []

      for month_str in sorted(missing_month_strs):
        try:
          year, month = map(int, month_str.split('-'))
          missing_months.append((year, month))
        except (ValueError, IndexError):
          continue

      logger.info(f"ğŸ” ìƒì„±í•  ì›”ê°„ ë¦¬í¬íŠ¸: {len(missing_months)}ê°œ")

      if missing_months:
        # Show missing months
        logger.info("\nğŸ“‹ ìƒì„± ëŒ€ìƒ ì›”:")
        for year, month in sorted(missing_months):
          month_str = f"{year}-{month:02d}"
          reports_count = len(months_with_reports.get(month_str, []))
          logger.info(f"  â€¢ {month_str} (ì£¼ê°„ ë¦¬í¬íŠ¸ {reports_count}ê°œ)")

      # 5. Generate missing reports
      result = await self.generate_missing_reports(missing_months)

      return result

    except Exception as e:
      logger.error(f"âŒ ë°°ì¹˜ ìƒì„± ì‹¤íŒ¨: {e}", exc_info=True)
      raise


async def main():
  """ë©”ì¸ í•¨ìˆ˜"""
  import argparse

  parser = argparse.ArgumentParser(
      description="ì›”ê°„ ë¦¬í¬íŠ¸ ë°°ì¹˜ ìƒì„±"
  )
  parser.add_argument(
      "--user-id",
      type=str,
      help="Slack User ID (í™˜ê²½ë³€ìˆ˜ NOTION_USER_DATABASE_MAPPINGì—ì„œ ìë™ íƒì§€ ê°€ëŠ¥)"
  )
  parser.add_argument(
      "--ai-provider",
      type=str,
      default="claude",
      choices=["gemini", "claude", "ollama"],
      help="AI ì œê³µì (ê¸°ë³¸ê°’: claude)"
  )
  parser.add_argument(
      "--batch-size",
      type=int,
      default=3,
      help="ë™ì‹œ ì²˜ë¦¬ ê°œìˆ˜ (ê¸°ë³¸ê°’: 3)"
  )
  parser.add_argument(
      "--all-users",
      action="store_true",
      help="ëª¨ë“  ìœ ì €ì— ëŒ€í•´ ë°°ì¹˜ ìƒì„±"
  )

  args = parser.parse_args()

  # Get user IDs
  user_ids = []

  if args.all_users:
    # Get all user IDs from environment
    user_db_mapping_str = os.getenv("NOTION_USER_DATABASE_MAPPING", "{}")
    try:
      user_db_mapping = json.loads(user_db_mapping_str)
      user_ids = list(user_db_mapping.keys())
      logger.info(f"âœ… {len(user_ids)}ëª…ì˜ ìœ ì € ë°œê²¬")
    except json.JSONDecodeError:
      logger.error("âŒ NOTION_USER_DATABASE_MAPPING íŒŒì‹± ì‹¤íŒ¨")
      sys.exit(1)

  elif args.user_id:
    user_ids = [args.user_id]

  else:
    # Try to get first user from environment
    user_db_mapping_str = os.getenv("NOTION_USER_DATABASE_MAPPING", "{}")
    try:
      user_db_mapping = json.loads(user_db_mapping_str)
      if user_db_mapping:
        user_ids = [list(user_db_mapping.keys())[0]]
        logger.info(f"âœ… ì²« ë²ˆì§¸ ìœ ì € ì‚¬ìš©: {user_ids[0]}")
      else:
        logger.error("âŒ ìœ ì €ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. --user-id ë˜ëŠ” --all-users ì˜µì…˜ì„ ì‚¬ìš©í•˜ì„¸ìš”.")
        sys.exit(1)
    except json.JSONDecodeError:
      logger.error("âŒ NOTION_USER_DATABASE_MAPPING íŒŒì‹± ì‹¤íŒ¨")
      sys.exit(1)

  # Process each user
  for user_id in user_ids:
    logger.info(f"\n{'='*60}")
    logger.info(f"ğŸ‘¤ ìœ ì €: {user_id}")
    logger.info(f"{'='*60}\n")

    try:
      generator = MonthlyReportBatchGenerator(
          user_id=user_id,
          ai_provider=args.ai_provider,
          batch_size=args.batch_size
      )

      result = await generator.run()

      # Print summary
      logger.info(f"\n{'='*60}")
      logger.info(f"ğŸ“Š ìµœì¢… ê²°ê³¼ (ìœ ì €: {user_id})")
      logger.info(f"{'='*60}")
      logger.info(f"ì´ ì‹œë„: {result['total']}ê°œ")
      logger.info(f"âœ… ì„±ê³µ: {result['success']}ê°œ")
      logger.info(f"âš ï¸ ê±´ë„ˆëœ€: {result['skipped']}ê°œ")
      logger.info(f"âŒ ì‹¤íŒ¨: {result['failed']}ê°œ")
      logger.info(f"{'='*60}\n")

    except Exception as e:
      logger.error(f"âŒ ìœ ì € {user_id} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
      continue

  logger.info("âœ… ëª¨ë“  ì²˜ë¦¬ ì™„ë£Œ!")


if __name__ == "__main__":
  asyncio.run(main())
